{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. \n",
        "Licensed under the MIT license. \n",
        "# Data Engineering\n",
        "\n",
        "After cleaning the data, we transform it in order to capture relevant metrics for ML modeling. These metrics  capture information related to:\n",
        "* Users & sessions\n",
        "* Buying behavior\n",
        "* Product details - brand, category, subcategories, product\n",
        "\n",
        "Results are written to the delta lake.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Library Imports\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pyspark\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read in Data from Delta Lake"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "data_lake_account_name = ''\n",
        "file_system_name = ''"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "full_dataset = ''"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "paths = [f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/transformed_data/cleaned_data_electronics']\n",
        "full_dataset = spark.read.format(\"delta\").load(*paths)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# add month & year, re-order columns\n",
        "cleaned_df = full_dataset.withColumn('month', month('event_time')) \\\n",
        "    .withColumn('year', year('event_time')) \\\n",
        "    .drop('category_code') \\\n",
        "    .select('user_id', 'year', 'month', 'event_type', 'product_id', 'category_id', 'category', 'subcategory', 'brand', 'price', 'user_session', 'event_time')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# write cleaned_df table to an intermediate spark table\n",
        "cleaned_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/intermediate_tables/cleaned_df\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# read cleaned_df table from intermediate spark table\n",
        "cleaned_df = spark.read.format(\"delta\").load(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/intermediate_tables/cleaned_df\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Transformation\n",
        "\n",
        "### Growth Indicator\n",
        "\n",
        "Classify customers as growth (1) or no growth (0) based on the month-over-month change in net revenue.\n",
        "\n",
        "1. Growth if there is a >10% net revenue increase\n",
        "1. No growth if there is a >10% net revenue decrease\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "user_id"
            ],
            "values": [
              "year"
            ],
            "yLabel": "year",
            "xLabel": "user_id",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": "{\"year\":{\"101875240\":2020,\"107620212\":2020,\"128968633\":2019,\"136662675\":2019,\"145611266\":2019}}",
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "# get monthly revenue\n",
        "growth = cleaned_df.filter(col('event_type') == 'purchase') \\\n",
        "    .withColumn('revenue', cleaned_df['price'].cast('double'))\\\n",
        "    .groupBy('user_id', 'year', 'month') \\\n",
        "    .sum('revenue') \\\n",
        "    .withColumnRenamed('sum(revenue)', 'total_net_revenue') \\\n",
        "    .orderBy('user_id', 'year', 'month')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "user_id"
            ],
            "values": [
              "year"
            ],
            "yLabel": "year",
            "xLabel": "user_id",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": "{\"year\":{\"430640726\":2020,\"436540545\":2020,\"461023190\":2019,\"476777607\":4039}}",
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "# get deltas for previous month\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import lag\n",
        "\n",
        "window_specs = Window.partitionBy('user_id').orderBy('user_id', 'year', 'month')\n",
        "\n",
        "growth_lag = growth.withColumn('last_month_revenue', lag(growth.total_net_revenue).over(window_specs).cast('double'))\n",
        "growth_delta = growth_lag.withColumn('delta_net_revenue', (growth_lag.total_net_revenue - growth_lag.last_month_revenue).cast('double'))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# identify growth vs. no growth customers\n",
        "# growth defined as +/-10% revenue month-over-month\n",
        "\n",
        "df_growth_a = growth_delta.withColumn('percent_delta_revenue', growth_delta['delta_net_revenue']/growth_delta['last_month_revenue'].cast('double'))\n",
        "df_growth = df_growth_a.withColumn('growth', \n",
        "        when(df_growth_a['percent_delta_revenue'] > .1, 1)\n",
        "        .when(df_growth_a['percent_delta_revenue'] < -.1, 0)) \\\n",
        "        .drop('last_month_revenue', 'delta_net_revenue', 'total_net_revenue', 'percent_delta_revenue') \\\n",
        "        .filter(col('growth').isNotNull())"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregated Metrics\n",
        "\n",
        "Transform data to produce metrics related to user sessions, buying behavior, and product categories. All features are aggregated on a per-user, per-month basis.\n",
        "\n",
        "### Session & Buying Metrics\n",
        "\n",
        "* Number of sessions\n",
        "* Average session duration\n",
        "* Average conversion rate\n",
        "* Average order value\n",
        "* Average cart abandon rate\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# sessions per user\n",
        "sessions_per_user_per_month = cleaned_df.groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(countDistinct('user_session').alias('sessions_per_user_per_month')) \\\n",
        "    .fillna({'sessions_per_user_per_month': 0}) \\\n",
        "    .orderBy('user_id', 'year', 'month')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# avg session duration\n",
        "# time between start & end of each session, aggregated per user per month\n",
        "session_durations = cleaned_df.groupBy('user_id', 'year', 'month', 'user_session') \\\n",
        "    .agg(\n",
        "        unix_timestamp(min('event_time')).alias('session_start_time'),\n",
        "        unix_timestamp(max('event_time')).alias('session_end_time')) \\\n",
        "    .withColumn('session_duration', col('session_end_time')-col('session_start_time')) \\\n",
        "    .drop('user_session', 'session_start_time', 'session_end_time')\n",
        "\n",
        "avg_session_duration_per_user_per_month = session_durations.groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(mean('session_duration').cast('double').alias('avg_session_duration_per_user_per_month')) \\\n",
        "    .orderBy('user_id', 'year', 'month')\n",
        "\n",
        "#avg_session_duration_per_user_per_month.orderBy(desc('avg_session_duration_per_user_per_month')).show(5)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# avg conversion rate\n",
        "# avg # purchases / # views per user per month\n",
        "avg_conversion_rate_per_user_per_month = cleaned_df.groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(\n",
        "        count(when(col('event_type') == 'view', True)).alias('num_views'),\n",
        "        count(when(col('event_type') == 'purchase', True)).alias('num_purchases')) \\\n",
        "    .fillna({'num_views': 0, 'num_purchases': 0}) \\\n",
        "    .withColumn('avg_conversion_rate_per_user_per_month', (col('num_purchases')/col('num_views')).cast('double')) \\\n",
        "    .drop('num_views', 'num_purchases') \\\n",
        "    .orderBy('user_id', 'year', 'month')\n",
        "\n",
        "#avg_conversion_rate_per_user_per_month.orderBy(desc('avg_conversion_rate_per_user_per_month')).show(5)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# avg order value\n",
        "# price per user per month, for purchases only\n",
        "avg_order_value_per_user_per_month = cleaned_df.filter(col('event_type') == 'purchase') \\\n",
        "    .groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(mean('price').cast('double').alias('avg_order_value_per_user_per_month')) \\\n",
        "    .orderBy('user_id', 'year', 'month')\n",
        "\n",
        "#avg_order_value_per_user_per_month.show(5)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# avg_cart_abandon_rate\n",
        "# items that were added to cart, but not purchased\n",
        "abandon_rate_per_session = cleaned_df.filter((col('event_type') == 'purchase') | (col('event_type') == 'cart')) \\\n",
        "    .groupBy('user_id', 'year', 'month', 'user_session', 'product_id') \\\n",
        "    .pivot('event_type').agg(count('product_id')) \\\n",
        "    .fillna({'cart':0, 'purchase':0}) \\\n",
        "    .withColumn('cart_abandon_rate', (col('cart')-col('purchase'))/col('cart'))\n",
        "\n",
        "avg_cart_abandon_rate = abandon_rate_per_session.groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(mean('cart_abandon_rate').cast('double').alias('avg_cart_abandon_rate'))\n",
        "\n",
        "#avg_cart_abandon_rate.show(5)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Brand, Subcategory, & Product Metrics\n",
        "\n",
        "For the top 5 most popular values in each product-related category (brand, subcategory, and product_id), identify the frequency of user clickstream interactions (product views, add to cart, and purchases)."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "user_id"
            ],
            "values": [
              "year"
            ],
            "yLabel": "year",
            "xLabel": "user_id",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": "{\"year\":{\"104655840\":2020,\"113868975\":2020,\"120701478\":4040,\"128968633\":6060,\"138365902\":2019,\"153449371\":4039,\"158131855\":2020,\"158971609\":2019,\"191365178\":2019,\"191555348\":2020,\"195082191\":2019}}",
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "# reusable function\n",
        "## event_type = clickstream activity (view, cart, purchase)\n",
        "## match_type = product-related column (brand, subcategory, product_id)\n",
        "\n",
        "def get_top_5(df, event_type, match_type):\n",
        "\n",
        "    # get list of top 5\n",
        "    top_5_list = df.filter(col('event_type')==event_type).groupBy(match_type).pivot('event_type') \\\n",
        "        .agg(count('user_session')).orderBy(desc(event_type)) \\\n",
        "        .select(match_type).limit(5).rdd.flatMap(lambda x: x).collect()\n",
        "        \n",
        "    # filter df for top 5\n",
        "    top_5_df = df.where(col(match_type).isin(top_5_list)) \\\n",
        "        .filter(col('event_type')==event_type) \\\n",
        "        .groupBy('user_id', 'year', 'month') \\\n",
        "        .pivot(match_type) \\\n",
        "        .agg(count('user_session'))\n",
        "\n",
        "    # reformat types / naming convention\n",
        "    if (event_type == 'view'):\n",
        "        event_type = 'viewed'\n",
        "    elif (event_type == 'cart'):\n",
        "        event_type = 'added'\n",
        "    else:\n",
        "        event_type = 'purchased'\n",
        "\n",
        "    # convert to binary & count columns\n",
        "    for i in range(1, len(top_5_list)+1):\n",
        "        i_name = top_5_list[i-1]\n",
        "        top_5_df = top_5_df.withColumn(f'{match_type}_{i_name}_{event_type}_binary', when(col(i_name).isNotNull(), 1).otherwise(0)) \\\n",
        "            .withColumnRenamed(f'{i_name}', f'{match_type}_{i_name}_{event_type}_count') \\\n",
        "            .fillna({f'{match_type}_{i_name}_{event_type}_count': 0})\n",
        "\n",
        "    return top_5_df"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# brands\n",
        "top_brands_viewed = get_top_5(cleaned_df, 'view', 'brand')\n",
        "top_brands_added = get_top_5(cleaned_df, 'cart', 'brand')\n",
        "top_brands_purchased = get_top_5(cleaned_df, 'purchase', 'brand')\n",
        "\n",
        "# subcategories\n",
        "top_subcategories_viewed = get_top_5(cleaned_df, 'view', 'subcategory')\n",
        "top_subcategories_added = get_top_5(cleaned_df, 'cart', 'subcategory')\n",
        "top_subcategories_purchased = get_top_5(cleaned_df, 'purchase', 'subcategory')\n",
        "\n",
        "# products\n",
        "top_products_viewed = get_top_5(cleaned_df, 'view', 'product_id')\n",
        "top_products_added = get_top_5(cleaned_df, 'cart', 'product_id')\n",
        "top_products_purchased = get_top_5(cleaned_df, 'purchase', 'product_id')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Join DataFrames into Single DataFrame"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# join dfs\n",
        "def join_dfs (df_list):\n",
        "    joined_df = df_growth\n",
        "    for l in df_list:\n",
        "        joined_df = joined_df.join(l, ['user_id', 'year', 'month'], how='left')\n",
        "    return joined_df\n",
        "\n",
        "features_df = join_dfs([sessions_per_user_per_month, \\\n",
        "    avg_session_duration_per_user_per_month, \\\n",
        "    avg_conversion_rate_per_user_per_month, \\\n",
        "    avg_order_value_per_user_per_month, \\\n",
        "    avg_cart_abandon_rate, \\\n",
        "    top_brands_viewed, top_brands_added, top_brands_purchased, \\\n",
        "    top_subcategories_viewed, top_subcategories_added, top_subcategories_purchased, \\\n",
        "    top_products_viewed, top_products_added, top_products_purchased\n",
        "    ]).fillna(0)\n",
        "\n",
        "# display(features_df.take(15))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Transformed Data to a Delta Table\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# write transformed data to spark table\n",
        "features_df.write.format('delta').mode('overwrite').option(\"overwriteSchema\", \"true\").save(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/transformed_data/transformed_data')"
      ],
      "attachments": {}
    }
  ]
}