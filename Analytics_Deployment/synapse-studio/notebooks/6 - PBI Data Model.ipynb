{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. \n",
        "Licensed under the MIT license. \n",
        "# Power BI Data Model\n",
        "\n",
        "Transform the cleaned dataset for reporting in Power BI, storing tables as CSV files in the Data Lake.\n",
        "\n",
        "The resulting data model includes four tables:\n",
        "\n",
        "1. Customer: user info, growth/no growth, & aggregated session metrics\n",
        "1. Activity: user clickstream activity, e.g. product views, purchases\n",
        "1. Products: reference table with additional product information\n",
        "1. Categories: reference table with additional product category information.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Library Imports\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pyspark\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read in Data from Delta Lake\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "data_lake_account_name = ''\n",
        "file_system_name = ''"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {},
      "source": [
        "paths = [f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/transformed_data/cleaned_data_electronics']\n",
        "full_dataset = spark.read.format(\"delta\").load(*paths)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {},
      "source": [
        "# add month & year, re-order columns\n",
        "cleaned_df = full_dataset.withColumn('month', month('event_time')) \\\n",
        "    .withColumn('year', year('event_time')) \\\n",
        "    .drop('category_code') \\\n",
        "    .select('user_id', 'year', 'month', 'event_type', 'product_id', 'category_id', 'category', 'subcategory', 'brand', 'price', 'user_session', 'event_time')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {},
      "source": [
        "# write cleaned_df table to an intermediate spark table\n",
        "cleaned_df.write.format(\"delta\").mode(\"overwrite\").save(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/intermediate_tables/cleaned_df\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {},
      "source": [
        "# read cleaned_df table from intermediate spark table\n",
        "cleaned_df = spark.read.format(\"delta\").load(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/intermediate_tables/cleaned_df\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Modeling\n",
        "\n",
        "Transform data to create four tables for reporting, each with a unique identifier (UID, product_id, or category_id) to be linked in Power BI."
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Customer Table\n",
        "\n",
        "**Growth indicator:** Classify customers as growth or no growth based on month-over-month change in net revenue.\n",
        "\n",
        "1. Growth if >10% net revenue increase\n",
        "1. No growth if >10% net revenue decrease\n",
        "1. No change if in between\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "user_id"
            ],
            "values": [
              "year"
            ],
            "yLabel": "year",
            "xLabel": "user_id",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": "{\"year\":{\"101875240\":2020,\"107620212\":2020,\"128968633\":2019,\"136662675\":2019,\"145611266\":2019}}",
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "# get monthly revenue\n",
        "growth = cleaned_df.filter(col('event_type') == 'purchase') \\\n",
        "    .withColumn('revenue', cleaned_df['price'].cast('double'))\\\n",
        "    .groupBy('user_id', 'year', 'month') \\\n",
        "    .sum('revenue') \\\n",
        "    .withColumnRenamed('sum(revenue)', 'total_net_revenue') \\\n",
        "    .orderBy('user_id', 'year', 'month')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "user_id"
            ],
            "values": [
              "year"
            ],
            "yLabel": "year",
            "xLabel": "user_id",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": "{\"year\":{\"430640726\":2020,\"436540545\":2020,\"461023190\":2019,\"476777607\":4039}}",
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "# get deltas for previous month\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import lag\n",
        "\n",
        "window_specs = Window.partitionBy('user_id').orderBy('user_id', 'year', 'month')\n",
        "\n",
        "growth_lag = growth.withColumn('last_month_revenue', lag(growth.total_net_revenue).over(window_specs).cast('double'))\n",
        "growth_delta = growth_lag.withColumn('delta_net_revenue', (growth_lag.total_net_revenue - growth_lag.last_month_revenue).cast('double'))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {},
      "source": [
        "# identify growth vs. no growth customers\n",
        "# growth defined as +/-10% revenue month-over-month\n",
        "\n",
        "df_growth_a = growth_delta.withColumn('percent_delta_revenue', growth_delta['delta_net_revenue']/growth_delta['last_month_revenue'].cast('double'))\n",
        "df_growth = df_growth_a.withColumn('growth', \n",
        "        when(df_growth_a['percent_delta_revenue'] > .1, 'growth')\n",
        "        .when(df_growth_a['percent_delta_revenue'] < -.1, 'decline')\n",
        "        .otherwise('no change')) \\\n",
        "        .drop('last_month_revenue', 'delta_net_revenue') \\\n",
        "        .filter(col('growth').isNotNull())"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Session & buying behavior:** Calculated on a per user, per month basis.\n",
        "\n",
        "* Number of sessions\n",
        "* Average session duration\n",
        "* Average conversion rate\n",
        "* Average order value\n",
        "* Average cart abandon rate\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {},
      "source": [
        "# sessions per user\n",
        "sessions_per_user_per_month = cleaned_df.groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(countDistinct('user_session').alias('sessions_per_user_per_month')) \\\n",
        "    .fillna({'sessions_per_user_per_month': 0}) \\\n",
        "    .orderBy('user_id', 'year', 'month')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {},
      "source": [
        "# avg session duration\n",
        "# time between start & end of each session, aggregated per user per month\n",
        "session_durations = cleaned_df.groupBy('user_id', 'year', 'month', 'user_session') \\\n",
        "    .agg(\n",
        "        unix_timestamp(min('event_time')).alias('session_start_time'),\n",
        "        unix_timestamp(max('event_time')).alias('session_end_time')) \\\n",
        "    .withColumn('session_duration', col('session_end_time')-col('session_start_time')) \\\n",
        "    .drop('user_session', 'session_start_time', 'session_end_time')\n",
        "\n",
        "avg_session_duration_per_user_per_month = session_durations.groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(mean('session_duration').cast('double').alias('avg_session_duration_per_user_per_month')) \\\n",
        "    .orderBy('user_id', 'year', 'month')\n",
        "\n",
        "#avg_session_duration_per_user_per_month.orderBy(desc('avg_session_duration_per_user_per_month')).show(5)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {},
      "source": [
        "# avg conversion rate\n",
        "# avg # purchases / # views per user per month\n",
        "avg_conversion_rate_per_user_per_month = cleaned_df.groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(\n",
        "        count(when(col('event_type') == 'view', True)).alias('num_views'),\n",
        "        count(when(col('event_type') == 'purchase', True)).alias('num_purchases')) \\\n",
        "    .fillna({'num_views': 0, 'num_purchases': 0}) \\\n",
        "    .withColumn('avg_conversion_rate_per_user_per_month', (col('num_purchases')/col('num_views')).cast('double')) \\\n",
        "    .drop('num_views', 'num_purchases') \\\n",
        "    .orderBy('user_id', 'year', 'month')\n",
        "\n",
        "#avg_conversion_rate_per_user_per_month.orderBy(desc('avg_conversion_rate_per_user_per_month')).show(5)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {},
      "source": [
        "# avg order value\n",
        "# price per user per month, for purchases only\n",
        "avg_order_value_per_user_per_month = cleaned_df.filter(col('event_type') == 'purchase') \\\n",
        "    .groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(mean('price').cast('double').alias('avg_order_value_per_user_per_month')) \\\n",
        "    .orderBy('user_id', 'year', 'month')\n",
        "\n",
        "#avg_order_value_per_user_per_month.show(5)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {},
      "source": [
        "# avg_cart_abandon_rate\n",
        "# items that were added to cart, but not purchased\n",
        "abandon_rate_per_session = cleaned_df.filter((col('event_type') == 'purchase') | (col('event_type') == 'cart')) \\\n",
        "    .groupBy('user_id', 'year', 'month', 'user_session', 'product_id') \\\n",
        "    .pivot('event_type').agg(count('product_id')) \\\n",
        "    .fillna({'cart':0, 'purchase':0}) \\\n",
        "    .withColumn('cart_abandon_rate', (col('cart')-col('purchase'))/col('cart'))\n",
        "\n",
        "avg_cart_abandon_rate = abandon_rate_per_session.groupBy('user_id', 'year', 'month') \\\n",
        "    .agg(mean('cart_abandon_rate').cast('double').alias('avg_cart_abandon_rate'))\n",
        "\n",
        "#avg_cart_abandon_rate.show(5)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Join all Customer DataFrames**\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {},
      "source": [
        "# join customer dfs\n",
        "def join_dfs (df_list):\n",
        "    joined_df = df_growth\n",
        "    for l in df_list:\n",
        "        joined_df = joined_df.join(l, ['user_id', 'year', 'month'], how='left')\n",
        "    return joined_df\n",
        "\n",
        "customers_joined = join_dfs([sessions_per_user_per_month, \\\n",
        "    avg_session_duration_per_user_per_month, \\\n",
        "    avg_conversion_rate_per_user_per_month, \\\n",
        "    avg_order_value_per_user_per_month, \\\n",
        "    avg_cart_abandon_rate])"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {},
      "source": [
        "# add unique identifier\n",
        "customers = customers_joined.withColumn('UID', concat(customers_joined['user_id'], lit('-'), customers_joined['year'], lit('-'), customers_joined['month']))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clickstream Activity Table\n",
        "\n",
        "A transaction table that lists each clickstream event, including product views, add to cart, and purchases."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {},
      "source": [
        "# filter to only rows where 'growth' is applicable, i.e. rows in customer table\n",
        "activity = cleaned_df.withColumn('UID', concat(cleaned_df['user_id'], lit('-'), cleaned_df['year'], lit('-'), cleaned_df['month'])) \\\n",
        "    .join(customers, ['UID'], how='right') \\\n",
        "    .select('UID', 'event_type', 'product_id')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Products Table\n",
        "\n",
        "A reference table with additional product information."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {},
      "source": [
        "products = cleaned_df.select('product_id', 'brand', 'price', 'category_id').dropDuplicates(['product_id'])"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categories Table\n",
        "\n",
        "A reference table with additional product category information."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {},
      "source": [
        "categories = cleaned_df.select('category_id', 'category', 'subcategory').dropDuplicates(['category_id'])"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Tables to Data Lake\n",
        "\n",
        "Persist the four tables to CSV files in the Data Lake for reporting.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {},
      "source": [
        "save_path = f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/reporting/'\n",
        "\n",
        "customers.coalesce(1).write.option('header', 'true').mode('overwrite').option(\"overwriteSchema\", \"true\").csv(save_path+'customers')\n",
        "activity.write.option('header', 'true').mode('overwrite').option(\"overwriteSchema\", \"true\").csv(save_path+'activity')\n",
        "products.coalesce(1).write.option('header', 'true').option(\"overwriteSchema\", \"true\").mode('overwrite').csv(save_path+'products')\n",
        "categories.coalesce(1).write.option('header', 'true').option(\"overwriteSchema\", \"true\").mode('overwrite').csv(save_path+'categories')"
      ],
      "attachments": {}
    }
  ]
}