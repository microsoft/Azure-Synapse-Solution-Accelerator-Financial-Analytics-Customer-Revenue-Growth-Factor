{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. \n",
        "Licensed under the MIT license. \n",
        "# ML Model Building\n",
        "\n",
        "Pre-process data and use the data to build a Spark machine learning model in this notebook using the following steps:\n",
        "\n",
        "1. Training-test split\n",
        "1. Data pre-processing (one-hot encoding, vectorizor)\n",
        "1. Build machine learning model\n",
        "1. Calculate model performance metrics\n",
        "1. Extract model feature importances\n",
        "1. Save results to data lake"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Library Imports\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pyspark\n",
        "spark = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
        "               .config(\"spark.jars.packages\", \"com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1\") \\\n",
        "               .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\") \\\n",
        "               .getOrCreate()\n",
        "from mmlspark.lightgbm import *\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.feature import *\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.tuning import *\n",
        "from pyspark.ml.evaluation import *\n",
        "from pyspark.ml.classification import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "spark.conf.set('spark.sql.execution.arrow.enabled', False)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read In Data From Delta Lake\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "data_lake_account_name = ''\n",
        "file_system_name = ''"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "df = spark.read.format(\"delta\").load(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/transformed_data/ml_data\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train-Test Split\n",
        "Split data into a 70-30 training-test split"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "(trainDF, testDF) = df.randomSplit([.7, .3], seed = 123)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML Pre-Processing & Model Building\n",
        "1. Pre-process data by encoding categorical columns and assembling them into a vector format expected for model building.\n",
        "2. Build a Spark pipeline binary classifier model to predict growth using LightGBM\n",
        "3. Use this model to score the test dataset to get model performance metrics"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Target column (label)\n",
        "target_col = 'growth'\n",
        "\n",
        "# ID columns\n",
        "id_col_1 = 'user_id'\n",
        "id_col_2 = 'year'\n",
        "id_col_3 = 'month'\n",
        "\n",
        "# Separate into Categorical, Target, and Numeric Columns\n",
        "\n",
        "# Create categorical column list with all of the columns that contain int and string values\n",
        "categorical_cols = ['brand_apple_purchased_binary', 'brand_samsung_purchased_binary', 'brand_xiaomi_purchased_binary', \n",
        "                    'brand_huawei_purchased_binary', 'brand_acer_purchased_binary', 'subcategory_smartphone_purchased_binary', \n",
        "                    'subcategory_audio_purchased_binary', 'subcategory_clocks_purchased_binary', \n",
        "                    'subcategory_tablet_purchased_binary', 'subcategory_telephone_purchased_binary', \n",
        "                    'product_id_1004856_purchased_binary', 'product_id_1004767_purchased_binary', \n",
        "                    'product_id_1005115_purchased_binary', 'product_id_4804056_purchased_binary', 'product_id_1004833_purchased_binary']\n",
        "\n",
        "numeric_cols = ['sessions_per_user_per_month', 'avg_session_duration_per_user_per_month', 'avg_conversion_rate_per_user_per_month',\n",
        "                'avg_order_value_per_user_per_month', 'avg_cart_abandon_rate']\n",
        "\n",
        "stages = [] # stages in our Pipeline\n",
        "\n",
        "# Category Indexing with StringIndexer - Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
        "string_indexes = [StringIndexer(inputCol = c, outputCol = 'idx_' + c, handleInvalid = 'keep') for c in categorical_cols]\n",
        "onehot_indexes = [OneHotEncoderEstimator(inputCols = ['idx_' + c], outputCols = ['ohe_' + c]) for c in categorical_cols]\n",
        "stages += string_indexes + onehot_indexes\n",
        "\n",
        "# Transform all numeric features into a vector using VectorAssembler\n",
        "assembler_inputs = ['ohe_' + c for c in categorical_cols] + numeric_cols\n",
        "assembler = VectorAssembler(inputCols = assembler_inputs, outputCol = 'features', handleInvalid = 'keep')\n",
        "stages += [assembler]\n",
        "\n",
        "# Create an indexed label from your target variable\n",
        "label_string_idx = StringIndexer(inputCol = target_col, outputCol = 'label', handleInvalid = 'keep')\n",
        "stages += [label_string_idx]\n",
        "\n",
        "# Set a random seed variable for reproducibility\n",
        "random_seed_val = 12345\n",
        "\n",
        "# Light GBM Classifier\n",
        "lgbm = LightGBMClassifier(learningRate = 0.1, numIterations = 100, numLeaves = 50)\n",
        "stages += [lgbm]\n",
        "\n",
        "lgbmPipeline = Pipeline(stages = stages)\n",
        "lgbmPipelineModel = lgbmPipeline.fit(trainDF)\n",
        "lgbmDF = lgbmPipelineModel.transform(testDF)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance Metrics\n",
        "Calculate classification model metrics using the test dataset"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "mce = MulticlassClassificationEvaluator()\n",
        "bce = BinaryClassificationEvaluator()\n",
        "\n",
        "accuracy = mce.setMetricName('accuracy').evaluate(lgbmDF)\n",
        "precision = mce.setMetricName('weightedPrecision').evaluate(lgbmDF)\n",
        "recall = mce.setMetricName('weightedRecall').evaluate(lgbmDF)\n",
        "f1 = mce.setMetricName('f1').evaluate(lgbmDF)\n",
        "auc = bce.setMetricName('areaUnderROC').evaluate(lgbmDF)\n",
        "\n",
        "# model metrics df\n",
        "model_metrics = spark.createDataFrame(\n",
        "    [\n",
        "        ('Accuracy', f'{accuracy:.2f}'),\n",
        "        ('Precision', f'{precision:.2f}'),\n",
        "        ('Recall', f'{recall:.2f}'),\n",
        "        ('F1 Score', f'{f1:.2f}'),\n",
        "        ('AUC', f'{auc:.2f}'),\n",
        "    ],\n",
        "    ['Metric', 'Value']\n",
        ")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "Metric"
            ],
            "values": [
              "Metric"
            ],
            "yLabel": "Metric",
            "xLabel": "Metric",
            "aggregation": "COUNT",
            "aggByBackend": false
          },
          "aggData": "{\"Metric\":{\"AUC\":1,\"Accuracy\":1,\"F1 Score\":1,\"Precision\":1,\"Recall\":1}}",
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "display(model_metrics)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Importances\n",
        "Use the model feature importances to determine the top revenue growth factors and their relative importances"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Custom function to extract feature names and importance - partly borrowed from https://gist.github.com/timlrx/1d5fdb0a43adbbe32a9336ba5c85b1b2#file-featureimportanceselector-py\n",
        "def ExtractFeatureImp(featureImp, df, featuresCol):\n",
        "    list_extract = []\n",
        "    for i in df.schema[featuresCol].metadata['ml_attr']['attrs']:\n",
        "        list_extract = list_extract + df.schema[featuresCol].metadata['ml_attr']['attrs'][i]\n",
        "    varlist = pd.DataFrame(list_extract)\n",
        "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
        "    return(varlist.sort_values('score', ascending = False))\n",
        "  \n",
        "varlist = ExtractFeatureImp(lgbmPipelineModel.stages[-1].getFeatureImportances(), lgbmDF, 'features')\n",
        "\n",
        "# important features df\n",
        "important_features = spark.createDataFrame(varlist)\n",
        "important_features = important_features.drop('idx')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "name"
            ],
            "values": [
              "score"
            ],
            "yLabel": "score",
            "xLabel": "name",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": "{\"score\":{\"avg_cart_abandon_rate\":505,\"avg_conversion_rate_per_user_per_month\":937,\"avg_order_value_per_user_per_month\":1117,\"avg_session_duration_per_user_per_month\":1174,\"ohe_brand_acer_purchased_binary_0\":34,\"ohe_brand_acer_purchased_binary_1\":0,\"ohe_brand_apple_purchased_binary_0\":56,\"ohe_brand_apple_purchased_binary_1\":3,\"ohe_brand_huawei_purchased_binary_0\":25,\"ohe_brand_huawei_purchased_binary_1\":0,\"ohe_brand_samsung_purchased_binary_0\":50,\"ohe_brand_samsung_purchased_binary_1\":6,\"ohe_brand_xiaomi_purchased_binary_0\":40,\"ohe_brand_xiaomi_purchased_binary_1\":3,\"ohe_product_id_1004767_purchased_binary_0\":20,\"ohe_product_id_1004767_purchased_binary_1\":2,\"ohe_product_id_1004833_purchased_binary_0\":11,\"ohe_product_id_1004833_purchased_binary_1\":0,\"ohe_product_id_1004856_purchased_binary_0\":18,\"ohe_product_id_1004856_purchased_binary_1\":0,\"ohe_product_id_1005115_purchased_binary_0\":21,\"ohe_product_id_1005115_purchased_binary_1\":1,\"ohe_product_id_4804056_purchased_binary_0\":26,\"ohe_product_id_4804056_purchased_binary_1\":1,\"ohe_subcategory_audio_purchased_binary_0\":79,\"ohe_subcategory_audio_purchased_binary_1\":9,\"ohe_subcategory_clocks_purchased_binary_0\":55,\"ohe_subcategory_clocks_purchased_binary_1\":6,\"ohe_subcategory_smartphone_purchased_binary_0\":66,\"ohe_subcategory_smartphone_purchased_binary_1\":11,\"ohe_subcategory_tablet_purchased_binary_0\":9,\"ohe_subcategory_tablet_purchased_binary_1\":0,\"ohe_subcategory_telephone_purchased_binary_0\":3,\"ohe_subcategory_telephone_purchased_binary_1\":0,\"sessions_per_user_per_month\":612}}",
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "display(important_features)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results to Data Lake\n",
        "Persist the model results to Delta tables on the Data Lake"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "important_features.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/important_features/important_features\")\n",
        "model_metrics.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/model_metrics/model_metrics\")"
      ],
      "attachments": {}
    }
  ]
}